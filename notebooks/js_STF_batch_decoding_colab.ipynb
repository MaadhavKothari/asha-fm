{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Giy1jAB52t9Z"
      },
      "source": [
        "# Start to Finish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8WPTZDC2t9b"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65-cQy9V2t9b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import librosa, librosa.display\n",
        "import numpy as np\n",
        "import random \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "#from spleeter.separator import Separator\n",
        "\n",
        "import moviepy.editor as mp\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA2VtvDI2t9c"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(linewidth=10000, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_NdAosF83xPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l11wGozO2t9d"
      },
      "source": [
        "# Params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/shortcuts/Asha FM'\n",
        "data_path"
      ],
      "metadata": {
        "id": "3k0aXIc16oz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "jl1uyNVv2t9d"
      },
      "outputs": [],
      "source": [
        "\n",
        "DRUM_AUDIO_PATH = '/content/drive/MyDrive/Asha FM/raw_data/audio/MDU.mp3'\n",
        "audio_path = '/content/drive/MyDrive/Asha FM/raw_data/audio/MDU.mp3'\n",
        "AUDIO_FILE_NAME = 'AUDIO_FILE'\n",
        "RAW_AUDIO_PATH = '/content/drive/MyDrive/Asha FM/raw_data/audio/MDU.mp3'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Divy-ZlV2t9d"
      },
      "outputs": [],
      "source": [
        "# IO\n",
        "# AUDIO_FILE_NAME = RAW_AUDIO_PATH.split('/')[-1].split('.')[0]\n",
        "\n",
        "# SPLIT_AUDIO_PATH = f\"../raw_data/audio/{AUDIO_FILE_NAME}/\"\n",
        "# DRUM_AUDIO_PATH = f\"{SPLIT_AUDIO_PATH}{AUDIO_FILE_NAME}-drums.wav\"\n",
        "\n",
        "VIDEO_SAVE_NAME = f\"{AUDIO_FILE_NAME}-asha.mp4\"\n",
        "VIDEO_SAVE_PATH = f\"../outputs/{VIDEO_SAVE_NAME}\"\n",
        "\n",
        "# GLOBAL\n",
        "# FIXED DURATION\n",
        "\n",
        "# AUDIO \n",
        "FRAME_RATE = 60\n",
        "HOP_WINDOW = 512\n",
        "\n",
        "# Images\n",
        "IMAGE_TIME_GAP = 1 # seconds, play with this\n",
        "IMAGE_FRAME_GAP = IMAGE_TIME_GAP * FRAME_RATE\n",
        "\n",
        "# VIDEO\n",
        "MAX_VIDEO_DURATION = 19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPn6g3s72t9d"
      },
      "source": [
        "# Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRZDD7FD2t9e"
      },
      "source": [
        "## Split the Audio into stems\n",
        "\n",
        "With spleeter by deezer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T7X2VhH2t9e"
      },
      "source": [
        "## Extracting Audio info from drum stem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nTq_SvjZ2t9e"
      },
      "source": [
        "### Extraction functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEsBoTU72t9e"
      },
      "outputs": [],
      "source": [
        "def get_audio_params(audio_path):\n",
        "    # Load song with 22050 sample rate\n",
        "    y, sr = librosa.load(audio_path, sr=22050)\n",
        "    audio_duration = librosa.get_duration(y=y, sr=sr)\n",
        "    \n",
        "    total_frames_float = audio_duration * FRAME_RATE\n",
        "    total_frames = math.ceil(total_frames_float)\n",
        "    \n",
        "    sample_rate = round(total_frames_float / audio_duration * HOP_WINDOW)\n",
        "    \n",
        "    return total_frames, sample_rate, audio_duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcHyfqfE2t9e"
      },
      "outputs": [],
      "source": [
        "def get_onset_info(audio_path, sample_rate):\n",
        "    # Load\n",
        "    y, sr = librosa.load(audio_path, sr=sample_rate)\n",
        "    \n",
        "    # Onset strengths and normalize\n",
        "    onset_strengths = librosa.onset.onset_strength(y=y, sr=sample_rate, aggregate=np.median)\n",
        "    onset_strengths = librosa.util.normalize(onset_strengths)\n",
        "    \n",
        "    # Onset timestamps and frames\n",
        "    onset_times = librosa.times_like(onset_strengths, sr=sample_rate)\n",
        "    onset_frames = onset_times * FRAME_RATE\n",
        "    \n",
        "    onset_info = np.concatenate([\n",
        "        onset_frames.reshape((-1, 1)),\n",
        "        onset_times.reshape((-1, 1)),\n",
        "        onset_strengths.reshape((-1, 1))\n",
        "    ], axis=1)\n",
        "    \n",
        "    # Beat times\n",
        "    beat_times = librosa.beat.beat_track(y=y, sr=sample_rate, units='time')[1]\n",
        "    \n",
        "    return y, onset_info, beat_times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FLmZOlk2t9e"
      },
      "source": [
        "### Using those functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAZj-0Bx2t9e"
      },
      "outputs": [],
      "source": [
        "total_frames, sample_rate, audio_duration = get_audio_params(DRUM_AUDIO_PATH)\n",
        "total_frames, sample_rate, audio_duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lrpLoeIG2t9e"
      },
      "outputs": [],
      "source": [
        "y, onset_info, beat_times = get_onset_info(DRUM_AUDIO_PATH, sample_rate)\n",
        "y.shape, onset_info.shape, beat_times.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qigfVZpq2t9e"
      },
      "source": [
        "## Create additional onset strength features\n",
        "\n",
        "- Linear Decay\n",
        "- Exponential Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crsV6pww2t9f"
      },
      "outputs": [],
      "source": [
        "def create_onset_features(onset_info, beat_times, lin_decay_time=0.25, exp_decay_rate=0.25, decay_magnification=True):\n",
        "    \n",
        "    fixed_decay_frames = int(lin_decay_time * FRAME_RATE)\n",
        "    \n",
        "    # Create column of zeroes as default value for both Linear and Exp Decay\n",
        "    onset_info = np.concatenate([onset_info, np.zeros((onset_info.shape[0], 1)), np.zeros((onset_info.shape[0], 1))], axis=1)\n",
        "    \n",
        "    # for each row\n",
        "    for i in range(onset_info.shape[0]):\n",
        "        # Skip the first value, makes life easy\n",
        "        if i == 0:\n",
        "            onset_info[i, 3] = 0\n",
        "        \n",
        "        \n",
        "        ## LINEAR\n",
        "        # If the timestamp is in beat_times, it's a peak\n",
        "        if onset_info[i, 1] in beat_times:\n",
        "            onset_info[i, 3] = onset_info[i, 2] # Linear Column\n",
        "            \n",
        "            # Decay Params\n",
        "            decay_factor = 1\n",
        "            if decay_magnification:\n",
        "                decay_factor *= (onset_info[i, 2] + 1)\n",
        "            \n",
        "            decay_frames = fixed_decay_frames * decay_factor\n",
        "            lin_decay_val = onset_info[i, 2] / decay_frames\n",
        "        \n",
        "        # Check if the previous value is zero or less than the decay_val -> 0\n",
        "        if onset_info[i - 1, 3] == 0. or abs(onset_info[i -1, 3]) < lin_decay_val:\n",
        "            pass\n",
        "        \n",
        "        # If previous value > 0, needs decay\n",
        "        elif onset_info[i - 1, 3] > 0: \n",
        "            onset_info[i, 3] = onset_info[i - 1, 3] - lin_decay_val\n",
        "        \n",
        "        \n",
        "        # EXPONENTIAL\n",
        "        # If the timestamp is in beat_times, it's a peak\n",
        "        if onset_info[i, 1] in beat_times:\n",
        "            onset_info[i, 4] = onset_info[i, 2] # Exp Column\n",
        "        \n",
        "        # Set current to zero if previous is zero or small number\n",
        "        elif onset_info[i - 1, 4] == 0 or onset_info[i - 1, 4] < 0.005: \n",
        "            pass\n",
        "        \n",
        "        # If previous value > 0, needs decay\n",
        "        elif onset_info[i - 1, 4] != 0: \n",
        "                onset_info[i, 4] = onset_info[i - 1, 4] * (1 - exp_decay_rate)\n",
        "    \n",
        "    return onset_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2HRL9LI2t9f"
      },
      "outputs": [],
      "source": [
        "y, onset_info, beat_times = get_onset_info(DRUM_AUDIO_PATH, sample_rate)\n",
        "onset_info = create_onset_features(onset_info, beat_times, lin_decay_time=0.25, exp_decay_rate=0.25, decay_magnification=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu7pj16r2t9f"
      },
      "source": [
        "# Model Stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "JRKAPfKU2t9f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Reshape, Conv2D, Conv2DTranspose, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "B9USs73-2t9f"
      },
      "outputs": [],
      "source": [
        "#ds = image_dataset_from_directory('../raw_data/zelle', label_mode=None, image_size=(448, 448), batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS9GIPAg2t9f"
      },
      "outputs": [],
      "source": [
        "#ds = ds.map(lambda x: x/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZaybPWT2t9f"
      },
      "outputs": [],
      "source": [
        "# imgs = ds.as_numpy_iterator().__next__()\n",
        "# imgs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "geA7plVH2t9f"
      },
      "source": [
        "### Model Architecture\n",
        "\n",
        "Because we are using load weights, we need to instantiate the model every time. This sucks for notebooks, but it will be fine once everything is packaged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNcXc3d72t9f"
      },
      "outputs": [],
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.random.normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oUsBE6R2t9f"
      },
      "outputs": [],
      "source": [
        "latent_dim = 200\n",
        "\n",
        "## Encoder\n",
        "\n",
        "input_image = Input(shape=(448, 448, 3))\n",
        "    \n",
        "x = Conv2D(32, (3, 3), padding='same', activation=\"relu\")(input_image)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), padding='same', activation=\"relu\")(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding='same', activation=\"relu\")(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), padding='same', activation=\"relu\")(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "# Encoder Build\n",
        "encoder = Model(input_image, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "#############################################\n",
        "\n",
        "## Decoder\n",
        "\n",
        "latent_inputs = Input(shape=(latent_dim,))  \n",
        "y = Dense(7*7*128, activation='tanh')(latent_inputs)\n",
        "y = Reshape((7, 7, 128))(y)\n",
        "\n",
        "y = Conv2DTranspose(256, (3, 3), strides=2, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(256, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(256, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(256, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "\n",
        "y = Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(128, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(128, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(128, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "\n",
        "y = Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(64, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(64, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "\n",
        "y = Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(32, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(32, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "\n",
        "y = Conv2DTranspose(16, (3, 3), strides=2, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(16, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "y = Conv2DTranspose(16, (3, 3), strides=1, padding='same', activation=\"relu\")(y)\n",
        "\n",
        "decoder_output = Conv2DTranspose(3, (3, 3), strides=2, padding='same', activation='sigmoid')(y)\n",
        "\n",
        "# Decoder Build\n",
        "decoder = Model(inputs=latent_inputs, outputs=decoder_output, name=\"decoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK7s6BLH2t9g"
      },
      "outputs": [],
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flPbZShi2t9g"
      },
      "source": [
        "## Instantiate Model and Load weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6RlwQcZ2t9g"
      },
      "outputs": [],
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "\n",
        "vae.load_weights('/content/drive/MyDrive/Asha FM/raw_data/model/e5100/vae_complex_model_epoch5100')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKA6Nm812t9g"
      },
      "source": [
        "### Predict\n",
        "\n",
        "Loads encoded_images numpy file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3kYQ_1t2t9g"
      },
      "outputs": [],
      "source": [
        "filename = \"/content/drive/MyDrive/Asha FM/raw_data/images/encoded_images.npy\"\n",
        "\n",
        "def load_images_from_file(filename):\n",
        "    latent_space = np.load(filename)\n",
        "    return latent_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VxP_Ou_2t9g"
      },
      "outputs": [],
      "source": [
        "N_IMAGES = math.ceil(audio_duration / IMAGE_TIME_GAP + 1)\n",
        "N_IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0cB1pMA2t9g"
      },
      "outputs": [],
      "source": [
        "encoded_images = load_images_from_file(\"/content/drive/MyDrive/Asha FM/raw_data/images/encoded_images.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hxTK0Kw2t9g"
      },
      "outputs": [],
      "source": [
        "#encoded_images = vae.decoder.predict(encoded_images[0:3 + N_IMAGES])[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESGs0kqL2t9g"
      },
      "outputs": [],
      "source": [
        "encoded_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFlv3x_y2t9g"
      },
      "outputs": [],
      "source": [
        "random_start_point = np.random.randint(0, encoded_images.shape[0] - N_IMAGES, size=(1))[0]\n",
        "random_start_point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwTk3ScR2t9h"
      },
      "source": [
        "# Create Interpolated Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDD4gkdJ2t9h"
      },
      "outputs": [],
      "source": [
        "def create_interp_vecs(N_IMAGES, encoded_images, min_factor=0.01, onset_info=onset_info):\n",
        "    # Empty lists to append new vectors to\n",
        "    lin_interp_vecs = []\n",
        "    exp_interp_vecs = []\n",
        "    \n",
        "    # We want to interate through the images to be able to interpolate between them\n",
        "    for i in range(N_IMAGES - 1):\n",
        "        \n",
        "        # Get start and stop latent vectors\n",
        "        start_vec = encoded_images[i]\n",
        "        end_vec = encoded_images[i + 1]\n",
        "        \n",
        "        # get step_vec between image_n and image_n + 1\n",
        "        step_vec = (end_vec - start_vec) / IMAGE_FRAME_GAP\n",
        "            \n",
        "        # We now need to create an image at every frame \n",
        "        # Mad props to Charlotte for making this way simpler than I was trying to make it\n",
        "        for j in range(IMAGE_FRAME_GAP):\n",
        "            \n",
        "            current_frame = IMAGE_FRAME_GAP * i + j\n",
        "            # Check to see if current_frame > total_frames : no point making extra images\n",
        "            if current_frame > int(onset_info[-1,0]):\n",
        "                break\n",
        "            lin_interp_vecs.append(start_vec + (step_vec * j * (onset_info[current_frame, 3] / min_factor + 1)))\n",
        "            exp_interp_vecs.append(start_vec + (step_vec * j * (onset_info[current_frame, 4] / min_factor + 1)))\n",
        "            \n",
        "    return np.array(lin_interp_vecs), np.array(exp_interp_vecs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1VOjVn_2t9h"
      },
      "outputs": [],
      "source": [
        "lin_interp_vecs, exp_interp_vecs = create_interp_vecs(N_IMAGES, encoded_images, min_factor=1, onset_info=onset_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ty2otrY9I66-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for create onset info\n",
        "lin_decay_time_list = [0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
        "exp_decay_rate_list = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55]\n",
        "\n",
        "onset_info_dict = {}\n",
        "\n",
        "for i, lin_decay_time in enumerate(lin_decay_time_list):\n",
        "    for j, exp_decay_rate in enumerate(exp_decay_rate_list):\n",
        "        onset_info_dict[(lin_decay_time, exp_decay_rate)] = create_onset_features(onset_info, beat_times, lin_decay_time, exp_decay_rate)\n",
        "for key, value in onset_info_dict.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "tdC3LgmaMOhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of min_factor values to use\n",
        "min_factor_list = [0.01, 0.05, 0.1, 0.25, 0.35, 0.5, 0.6, 0.75, 0.9, 0.99]\n",
        "\n",
        "# Define empty dictionaries to store the results\n",
        "lin_interp_vecs_dict = {}\n",
        "exp_interp_vecs_dict = {}\n",
        "\n",
        "# Loop over the list of min_factors and call create_interp_vecs function for each\n",
        "for min_factor in min_factor_list:\n",
        "    lin_interp_vecs, exp_interp_vecs = create_interp_vecs(N_IMAGES, encoded_images, min_factor, onset_info)\n",
        "    lin_interp_vecs_dict[f\"lin_interp_vecs_{min_factor}\"] = lin_interp_vecs\n",
        "    exp_interp_vecs_dict[f\"exp_interp_vecs_{min_factor}\"] = exp_interp_vecs\n",
        "\n",
        "# Print the dictionaries\n",
        "print(lin_interp_vecs_dict)\n",
        "print(exp_interp_vecs_dict)"
      ],
      "metadata": {
        "id": "PJDM3HdEGI_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZMqeU6P2t9h"
      },
      "outputs": [],
      "source": [
        "lin_interp_vecs.shape, exp_interp_vecs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAOwf0mr2t9h"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "import os\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Asha FM/raw_data/images/processed_images'\n",
        "\n",
        "\n",
        "def create_interp_imgs(decoder, lin_interp_vecs, exp_interp_vecs, batch_size=1, save_path=save_path):\n",
        "    # Linear Images\n",
        "    batch_memory = 500 * 1024 * 1024  # 500 MB\n",
        "\n",
        "    num_lin_imgs = len(lin_interp_vecs)\n",
        "    lin_interp_imgs = []\n",
        "    for i in range(0, num_lin_imgs, batch_size):\n",
        "        batch_vecs = lin_interp_vecs[i:i+batch_size]\n",
        "        batch_imgs = decoder.predict(batch_vecs)\n",
        "        batch_imgs = (batch_imgs * 255).astype('uint8')\n",
        "        lin_interp_imgs.append(batch_imgs)\n",
        "        print(f\"Processed {i+batch_size} linear images\")\n",
        "        if save_path and i % (500 * 1024 * 1024 // batch_memory) == 0:\n",
        "            if len(lin_interp_imgs) > 0:\n",
        "                np.save(os.path.join(save_path, f\"lin_interp_imgs_{i}.npy\"), np.concatenate(lin_interp_imgs, axis=0))\n",
        "                lin_interp_imgs = []\n",
        "        K.clear_session()\n",
        "    if len(lin_interp_imgs) > 0:\n",
        "        lin_interp_imgs = np.concatenate(lin_interp_imgs, axis=0)\n",
        "        if save_path:\n",
        "            np.save(os.path.join(save_path, f\"lin_interp_imgs_{num_lin_imgs}.npy\"), lin_interp_imgs)\n",
        "    \n",
        "    # Exponential Images\n",
        "    num_exp_imgs = len(exp_interp_vecs)\n",
        "    exp_interp_imgs = []\n",
        "    for i in range(0, num_exp_imgs, batch_size):\n",
        "        batch_vecs = exp_interp_vecs[i:i+batch_size]\n",
        "        batch_imgs = decoder.predict(batch_vecs)\n",
        "        batch_imgs = (batch_imgs * 255).astype('uint8')\n",
        "        exp_interp_imgs.append(batch_imgs)\n",
        "        print(f\"Processed {i+batch_size} exponential images\")\n",
        "        if save_path and i % (500 * 1024 * 1024 // batch_memory) == 0:\n",
        "            if len(exp_interp_imgs) > 0:\n",
        "                np.save(os.path.join(save_path, f\"exp_interp_imgs_{i}.npy\"), np.concatenate(exp_interp_imgs, axis=0))\n",
        "                exp_interp_imgs = []\n",
        "        K.clear_session()\n",
        "    if len(exp_interp_imgs) > 0:\n",
        "        exp_interp_imgs = np.concatenate(exp_interp_imgs, axis=0)\n",
        "        if save_path:\n",
        "            np.save(os.path.join(save_path, f\"exp_interp_imgs_{num_exp_imgs}.npy\"), exp_interp_imgs)\n",
        "    \n",
        "    return lin_interp_imgs, exp_interp_imgs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "tags": [],
        "id": "IziCjSSr2t9h"
      },
      "outputs": [],
      "source": [
        "lin_imgs, exp_imgs = create_interp_imgs(vae.decoder, lin_interp_vecs=lin_interp_vecs, exp_interp_vecs=exp_interp_vecs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXtQHc4w2t9h"
      },
      "outputs": [],
      "source": [
        "def concatenate_lin_interp_imgs(save_path, num_lin_imgs):\n",
        "    lin_interp_imgs = []\n",
        "    for i in range(num_lin_imgs):\n",
        "        file_path = os.path.join(save_path, f\"lin_interp_imgs_{i}.npy\")\n",
        "        if os.path.exists(file_path):\n",
        "            lin_interp_imgs.append(np.load(file_path))\n",
        "    lin_interp_imgs = np.concatenate(lin_interp_imgs, axis=0)\n",
        "    return lin_interp_imgs\n",
        "\n",
        "def concatenate_export_interp_imgs(save_path, num_exp_imgs):\n",
        "    exp_interp_imgs = []\n",
        "    for i in range(num_exp_imgs):\n",
        "        file_path = os.path.join(save_path, f\"exp_interp_imgs_{i}.npy\")\n",
        "        if os.path.exists(file_path):\n",
        "            exp_interp_imgs.append(np.load(file_path))\n",
        "    exp_interp_imgs = np.concatenate(exp_interp_imgs, axis=0)\n",
        "    return exp_interp_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tej0xzK2t9h"
      },
      "outputs": [],
      "source": [
        "num_lin_imgs = len(lin_interp_vecs)\n",
        "num_exp_imgs = len(exp_interp_vecs)\n",
        "\n",
        "interp_imgs = concatenate_lin_interp_imgs(save_path, num_lin_imgs)\n",
        "exp_imgs = concatenate_lin_interp_imgs(save_path, num_exp_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qt3waOk2t9h"
      },
      "source": [
        "# Create AV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy2z4AT12t9h"
      },
      "outputs": [],
      "source": [
        "def create_video_with_audio(interp_imgs):\n",
        "    \n",
        "    # Load the audio file\n",
        "    audio_clip = mp.AudioFileClip(RAW_AUDIO_PATH)\n",
        "    \n",
        "    # Needed for some reason?\n",
        "    frames = [mp.ImageClip(interp_img).set_duration(1/FRAME_RATE) for interp_img in interp_imgs]\n",
        "    \n",
        "    # Combine the frames into a video clip\n",
        "    video_clip = mp.concatenate_videoclips(frames, method='chain')\n",
        "    \n",
        "    # Overlay the audio on the video clip\n",
        "    final_clip = video_clip.set_audio(audio_clip)\n",
        "    \n",
        "    # Write the final video clip to file\n",
        "    final_clip.write_videofile(\"donk.mp4\", fps=FRAME_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "eXp_Vxj72t9h"
      },
      "outputs": [],
      "source": [
        "VIDEO_SAVE_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_nNp4cn2t9h"
      },
      "outputs": [],
      "source": [
        "create_video_with_audio(interp_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "YJR4JEJx2t9i"
      },
      "outputs": [],
      "source": [
        "print(datetime.now() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "334aB0cd2t9i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSohK5qt2t9i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}